---

- name: fluentd-load-balancer-awsnlb | ec2_instance_info
  ec2_instance_info:
    filters:
      "tag:hosttype": "fluentd"
      "instance-state-name": ["running"]
    aws_access_key: "{{ cluster_vars[buildenv].aws_access_key }}"
    aws_secret_key: "{{ cluster_vars[buildenv].aws_secret_key }}"
    region: "{{cluster_vars.region}}"
  delegate_to: localhost
  run_once: true
  register: r__ec2_instance_info

- name: fluentd-load-balancer-awsnlb | r__ec2_instance_info
  debug: msg="{{r__ec2_instance_info}}"
  run_once: true

- name: fluentd-load-balancer-awsnlb | create elb_target_group
  elb_target_group:
    aws_access_key: "{{ cluster_vars[buildenv].aws_access_key }}"
    aws_secret_key: "{{ cluster_vars[buildenv].aws_secret_key }}"
    region: "{{cluster_vars.region}}"
    name: "{{cluster_name}}-{{item.1.port}}-{{'int' if item.0=='internal' else 'ext'}}"
    protocol: "{% if 'config' in item.1 and 'transport udp' in item.1.config %}UDP{% else %}TCP{% endif %}"
    port: "{{ item.1.port }}"
    vpc_id: "{{ r__ec2_instance_info.instances | json_query(\"[].vpc_id | [0]\") }}"
#    deregistration_connection_termination: "{{ false if 'config' not in item.1 or 'transport udp' not in item.1.config else true }}"
    deregistration_delay_timeout: 30
    health_check_port: "{{ item.1.port if 'config' not in item.1 or 'transport udp' not in item.1.config else 22 }}"
    health_check_protocol: "TCP"
    health_check_interval: 10
    stickiness_enabled: no
    successful_response_codes: "200,250-260"
    targets: "{{ r__ec2_instance_info.instances | json_query(\"[].{Id: instance_id, Port: `\" + item.1.port|string + \"`}\") }}"
    state: present
  delegate_to: localhost
  run_once: true
  register: r__elb_target_group
  with_nested:
    - "{{ loadbalancer.awsnlb_schemes }}"
    - "{{ fluentd.conffile.sources_multi_worker | json_query(\"[?contains(keys(@), `port`)]\") }}"

- name: fluentd-load-balancer-awsnlb | r__elb_target_group
  debug: msg="{{r__elb_target_group}}"
  run_once: true

- name: fluentd-load-balancer-awsnlb | Create an N/ELB and attach listeners
  elb_network_lb:
    aws_access_key: "{{ cluster_vars[buildenv].aws_access_key }}"
    aws_secret_key: "{{ cluster_vars[buildenv].aws_secret_key }}"
    region: "{{cluster_vars.region}}"
    name: "{{cluster_name}}-{{'int' if item.0=='internal' else 'ext'}}"
    subnets: "{{ r__ec2_instance_info.instances | json_query(\"[].network_interfaces[].subnet_id\") }}"
    cross_zone_load_balancing: yes
    scheme: "{{ item.0 }}"
    listeners: "{{ item.1 | json_query(\"[].{Protocol: protocol, Port: port, DefaultActions: [{Type: 'forward', TargetGroupName: target_group_name}]}\") }}"
    state: present
    wait: yes
  delegate_to: localhost
  run_once: true
  register: r__elb_network_lb
  loop: "{{ r__elb_target_group.results | groupby('item.0') }}"

- name: fluentd-load-balancer-awsnlb | r__elb_network_lb
  debug: msg="{{r__elb_network_lb}}"
  run_once: true


- name: fluentd-load-balancer-awsnlb | Gather info for pre-existing Hosted Zones (public and/or private)
  route53_info:
    aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
    aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
    query: hosted_zone
  delegate_to: localhost
  register: r__route53_info__zones

- name: fluentd-load-balancer-awsnlb | r__route53_info__zones
  debug: msg="{{r__route53_info__zones}}"
  run_once: true

- name: fluentd-load-balancer-awsnlb | create CNAME(s)
  route53:
    aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
    aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
    state: present
    zone: "{{cluster_vars.dns_nameserver_zone}}"
    record: "{{loadbalancer.url}}"
    type: CNAME
    ttl: 30
    value: "{{ item.0.dns_name }}"
    private_zone: "{{ item.1.Config.PrivateZone }}"
    overwrite: true
  with_nested:
    - "{{ r__elb_network_lb.results }}"
    - "{{ r__route53_info__zones.HostedZones | json_query(\"[?Name==`\" + cluster_vars.dns_nameserver_zone + \".`]\") }}"
  delegate_to: localhost
  run_once: true
  when: loadbalancer.url is defined and loadbalancer.url != ''  and  ((item.0.item.0 == 'internal' and item.1.Config.PrivateZone|bool) or (item.0.item.0 == 'internet-facing' and not item.1.Config.PrivateZone|bool) )

#- name: fluentd-load-balancer-awsnlb | Wait for the NLB to be fully UP   (NOTE - only works if target is valid)
#  wait_for:
#    port: "{{ target_ports | first }}"
#    host: '{{ r__elb_network_lb.dns_name }}'
#  run_once: true
